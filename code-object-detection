import os
# wget is used to download files from URLs github:ansonnn07
import wget
# shutil is used to move files
import shutil
import tensorflow as tf

#data preparation
root_path= r'C:\Users\User\Desktop\oject detection'
image_path= os.path.join(root_path,'images')
annotation_path= os.path.join(root_path, 'Annotations')

from sklearn.model_selection import train_test_split
from imutils import paths

#for rerun remove tfrecord files and label map
train_tf=os.path.join(annotation_path,'train.record')
test_tf= os.path.join(annotation_path, 'test_record')
label_map_pbtxt=os.path.join(annotation_path, 'label_map.pbtxt')

for file_to_remove in [train_tf,test_tf,label_map_pbtxt]:
        if os.path.exists(file_to_remove):
            os.remove(file_to_remove)
            
#get images
seed=12345
image_path_sorted= sorted(paths.list_images(image_path))
print(f'Total images= {len(image_path_sorted)}')

#get annotations path then sort 
label_path_sorted= sorted(os.listdir(annotation_path))
label_path_sorted=[os.path.join(annotation_path,i) for i in label_path_sorted] 

#perform train test split
test_ratio=0.2
train_ratio= 1- test_ratio

print("Splitting into train:test dataset",f"with ratio of {train_ratio:2f}:{test_ratio:2f}")

x_train,x_test,y_train,y_test=train_test_split(image_path_sorted,label_path_sorted, test_size=test_ratio, random_state=seed)

print(len(x_test))

#create traintest folder for images n annotation
data_dir=os.path.join(root_path,'data')

if not os.path.exists(data_dir):
    print(f'[INFO] Creating folder "data" at {data_dir}')
    os.makedirs(data_dir)
    
#create function to copy file into folder
def copy_images(image_path,label_path,destination_folder_name):
    assert destination_folder_name in ("train", "validation", "test")
    image_dest=os.path.join(data_dir,destination_folder_name)
    
    print(f"[INFO] copying files from {os.path.dirname(image_path[0])} to {image_dest}")
    #if dest folder exist, clear content
    if os.path.exists(image_dest):
        shutil.rmtree(image_dest, ignore_error=False)
        
    if not os.path.exists(image_dest):
        os.makedirs(image_dest)
        
    for image_path, label_path in zip(image_path,label_path):
        #copy images n label file into dest folder
        shutil.copy2(image_path,image_dest)
        shutil.copy2(label_path,image_dest)
            
#use copy_image function to creat train test folders
copy_images(x_train, y_train, 'train')
copy_images(x_test, y_test, 'test')

print(f"[INFO] Files copied successfully")

#training for object detection

pretrain_model_url='http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'
pretrain_model_name= pretrain_model_url.split("/")[-1].split(".tar.gz")[0]

custom_model_name=f'my_{pretrain_model_name}'
label_map_name= 'label_map.pbtxt'

api_model_path= r'C:\Users\User\Documents\Tensorflow\models'

#creat dictionary for all paths

paths={
       'ROOT_PATH':root_path,
       'APIMODEL_PATH':api_model_path,
       'ANNOTATION_PATH': annotation_path,
       'IMAGE_PATH': image_path,
       'DATA_PATH': data_dir,
       'MODEL_PATH': os.path.join(root_path, 'models'),
       'PRETRAINED_MODEL_PATH': os.path.join(root_path,'pretrain-models'),
       'CHECKPOINT_PATH': os.path.join(root_path, 'models', custom_model_name),
       'OUTPUT_PATH': os.path.join(root_path, 'models', custom_model_name, 'export'),
       'TFJS_PATH': os.path.join(root_path, 'models', custom_model_name, 'tfjsexport'),
       'TFLITE_PATH': os.path.join(root_path, 'models', custom_model_name, 'tfliteexport')
        }

files={
       'PIPELINE_CONFIG': os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config'),
       'GENERATE_TF_RECORD': os.path.join(root_path, 'utils','generate_tfrecord.py'),
       'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], label_map_name)
        }


#download pretrained model
import tarfile
import object_detection

download_path= os.path.join(root_path,'downloads')

if not os.path.exists(download_path):
    os.makedirs(download_path)

#

if not os.path.exists(os.path.join(paths['PRETRAINED_MODEL_PATH'],pretrain_model_name)):
    wget.download(pretrain_model_url,download_path)
    pretrained_tarfile_name = pretrain_model_name + '.tar.gz'    
    pretrained_tarfile = os.path.join(download_path,pretrained_tarfile_name)
    #Extract the zipped file to the specific path    
    with tarfile.open(os.path.join(download_path,pretrained_tarfile)) as opened_file:
        opened_file.extractall(paths['PRETRAINED_MODEL_PATH'])
    os.remove(pretrained_tarfile)

# Create label map file
CLASS_NAMES = ['facemask']

with open(files['LABELMAP'],'w') as f:
    for idx, label in enumerate(CLASS_NAMES,start=1):
        f.write("item { \n")
        f.write(f"\tname: '{label}'\n")
        f.write(f"\tid: {idx}\n")
        f.write("}\n")

#Double check the written file
print(files['LABELMAP'])
with open(files['LABELMAP']) as f:
    print(f.read())
    
#%%
#2.7. Create label map dictionary
from object_detection.utils import label_map_util

#Show label map, if the file can be loaded by the API then the file is generated
#correctly.

label_map = label_map_util.load_labelmap(files['LABELMAP'])
label_map_dict = label_map_util.get_label_map_dict(label_map)
print(label_map_dict)

#Copy the abel map file to the export folder
shutil.copy2(files['LABELMAP'], paths['OUTPUT_PATH'])

#%%
#2.8. Create TF Records
command_train = f'python "{files["GENERATE_TF_RECORD"]}" -x "{os.path.join(paths["DATA_PATH"],"train")}" -e jpg png -l "{files["LABELMAP"]}" -o "{os.path.join(paths["ANNOTATION_PATH"],"train.record")}"'
print(command_train)
os.system(command_train)

command_test = f'python "{files["GENERATE_TF_RECORD"]}" -x "{os.path.join(paths["DATA_PATH"],"test")}" -e jpg png -l "{files["LABELMAP"]}" -o "{os.path.join(paths["ANNOTATION_PATH"],"test.record")}"'
print(command_test)
os.system(command_test)

#%%
#2.9. Copy model config to our custom model folder
original_config = os.path.join(paths['PRETRAINED_MODEL_PATH'],PRETRAINED_MODEL_NAME,'pipeline.config')
print(original_config)
print("New custom config file will be inside this folder: ", paths['CHECKPOINT_PATH'])
shutil.copy2(original_config,paths['CHECKPOINT_PATH'])

"""
Note: pipeline.config will be created in where paths['CHECKPOINT_PATH'] points to,
which is pointed by files['PIPELINE_CONFIG']
"""

#%%
#2.9. Edit pipeline config file for transfer learning
import tensorflow as tf
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format

#Your pipeline config file is here
print(files['PIPELINE_CONFIG'])
#Check the config file
config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])
print(type(config['model']))

#%%
#Apply transfer learning
#2.9.1. Hyperparameters and options to change
number_of_classes = len(CLASS_NAMES)
batch_size = 1
fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'],PRETRAINED_MODEL_NAME,'checkpoint','ckpt-0')
fine_tune_checkpoint_type = "detection"
label_map_path = files['LABELMAP']
train_tfrecord = os.path.join(paths['ANNOTATION_PATH'],'train.record')
test_tfrecord = os.path.join(paths['ANNOTATION_PATH'],'test.record')

#2.9.2. Apply the changes
#(a) Change the number of classes
config_util._update_num_classes(config['model'], number_of_classes)
#(b) Change batch size
config_util._update_batch_size(config, batch_size)
#(c) Change fine tune checkpoint
config['train_config'].fine_tune_checkpoint = fine_tune_checkpoint
#(d) Change fine tune checkpoint type
config['train_config'].fine_tune_checkpoint_type = fine_tune_checkpoint_type
#(e) Change label map path
config_util._update_label_map_path(config, label_map_path)
#(f) Change tfrecord path for both train and test
config_util._update_tf_record_input_path(config['train_input_config'], train_tfrecord)
config_util._update_tf_record_input_path(config['eval_input_configs'][0], test_tfrecord)
#(g) Generate pipeline config to our custom model folder
os.remove(files['PIPELINE_CONFIG'])
pipeline_config = config_util.create_pipeline_proto_from_configs(config)
config_util.save_pipeline_config(pipeline_config, paths['CHECKPOINT_PATH'])

#%%
#3. Model training
#Call the python script from objection detection model folder
TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'],'research','object_detection','model_main_tf2.py')

#Define our training steps (epochs), you can start with lower number to test first, then
#train for at least 2000 steps (recommended, if you want decent result)
epochs = 300

#Run the python command to execute the training
command_model_training = f'python "{TRAINING_SCRIPT}" --model_dir="{paths["CHECKPOINT_PATH"]}" --pipeline_config_path="{files["PIPELINE_CONFIG"]}" --num_train_steps={epochs}'
print(command_model_training)
os.system(command_model_training)

#%%
#4. Model evaluation
command_eval = f'python "{TRAINING_SCRIPT}" --model_dir="{paths["CHECKPOINT_PATH"]}" --pipeline_config_path="{files["PIPELINE_CONFIG"]}" --checkpoint_dir="{paths["CHECKPOINT_PATH"]}"'
print(command_eval)
os.system(command_eval)

#%%
#5. Export model
#5.1. Export model using the script
FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'],'research','object_detection','exporter_main_v2.py')
command_export = f'python "{FREEZE_SCRIPT}" --input_type=image_tensor --pipeline_config_path="{files["PIPELINE_CONFIG"]}" --trained_checkpoint_dir="{paths["CHECKPOINT_PATH"]}" --output_directory="{paths["OUTPUT_PATH"]}"'
print(command_export)
os.system(command_export)

#%%
#5.2. Zip the custom model
custom_model_file = CUSTOM_MODEL_NAME + '.tar.gz'
with tarfile.open(os.path.join(paths['OUTPUT_PATH'],custom_model_file),"w:gz") as tar:
    tar.add(paths['OUTPUT_PATH'])

#%%
#6. Load the trained model
#6.1. Check where your saved model is
print("Saved model in: \n", paths['OUTPUT_PATH']) 

#6.2. Load the saved model
from object_detection.utils import visualization_utils as viz_utils
import matplotlib.pyplot as plt

PATH_TO_SAVED_MODEL = os.path.join(paths['OUTPUT_PATH'],'saved_model')

print('Loading model...', end='')
start_time = time.perf_counter()
#Load the saved model with tensorflow method
detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)
end_time = time.perf_counter()
print(f'Done! Loading model took {end_time-start_time} seconds.')

#%%
#Load label map data
PATH_TO_LABELS = files['LABELMAP']
category_idx = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,use_display_name=True)
print(category_idx)

#%%
#7. Deployment
#7.1. Detect from an image
from imutils.paths import list_images
import numpy as np

#Function to load image
def load_image_into_numpy_array(path):
    """Load an image from file into a numpy array.
    Puts image into numpy array of shape (height, width, channels), where channels=3 for RGB to feed into tensorflow graph.
    Args:
      path: the file path to the image
    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    """
    img = cv2.imread(path)
    #Convert from OpenCV BGR format to RGB format
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return np.array(img)

#Function to deploy model and return prediction results 
def detect(image_np):
    start_t = time.perf_counter()
    #Running the inference on the image specified by the image path
    #The input needs to be a tensor, convert it using tf.convert_to_tensor
    input_tensor = tf.convert_to_tensor(image_np)
    #The model is expecting a batch images, allbeit a batch size 1.
    #We need to add one dimension that specify the batch size
    input_tensor = input_tensor[tf.newaxis,...]
    # or...
    # input_tensor = tf.expand_dims(input_tensor, axis=0)
    
    #Running detection using the loaded model
    detections = detect_fn(input_tensor)
    
    #All outputs are in batch tensors
    #Convert to numpy arrays, and take index [0] to remove the batch dimension.
    #We are only interested in the first num_detections.
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0,:num_detections].numpy() for key, value in detections.items()}
    detections['num_detections'] = num_detections
    
    #detection_classes should be int
    detections['detections_classes'] = detections['detection_classes'].astype(np.int64)
    end_t = time.perf_counter()
    print(f'[INFO] Done inference. [{end_t-start_t:.2f} seconds]')

    return detections

#Function to draw detected objects onto the image
def draw_results(detections, image_np, min_score_thresh=0.6):
    label_id_offset = 1
    image_np_with_detections = image_np.copy()
    viz_utils.visualize_boxes_and_labels_on_image_array(image_np_with_detections, detections['detection_boxes'],
                                                        detections['detection_classes'],detections['detection_scores'],
                                                        category_idx,use_normalized_coordinates=True,max_boxes_to_draw=20,
                                                        min_score_thresh=min_score_thresh,agnostic_mode=False)
    return image_np_with_detections

#Run inference on single image
#P(object) threshold (you can adjust this, if lower means more detections, at the risk of more false positives)
MIN_CONF_THRESH = 0.5

#Randomly select one image from img_paths
#Or you can just specify the path of any image you like.
random_image_path = r"C:\Users\User\Downloads\downloaded_img\images (10).jpg"

image_np = load_image_into_numpy_array(random_image_path)
print(f'[INFO] Detecting from the image: {random_image_path} ...')
detections = detect(image_np)
image_np_with_detections = draw_results(detections, image_np,min_score_thresh=MIN_CONF_THRESH)

fig = plt.figure()
fig.set_size_inches(10,10)
plt.imshow(image_np_with_detections)
plt.show()

#%%
#7.2. Detect from a random sets of images
random_image_path = r'C:\Users\User\Desktop\obj.jpg'
image_list = list(list_images(random_image_path))
#Change confidence threshold
MIN_CONF_THRESH = 0.35
for p in np.random.choice(image_list,4,replace=False):
    image_np = load_image_into_numpy_array(p)
    print(f'[INFO] Detecting from the image: {random_image_path} ...')
    detections = detect(image_np)
    image_np_with_detections = draw_results(detections, image_np,min_score_thresh=MIN_CONF_THRESH)

    fig = plt.figure()
    fig.set_size_inches(10,10)
    plt.imshow(image_np_with_detections)
    
plt.show()

#%%
#8. Real time detection with webcam
camera = cv2.VideoCapture(0)

while camera.isOpened():
    ret, frame = camera.read()
    if not ret:
        break
    
    #convert to numpy array
    image_np = np.array(frame)
    
    #Run inference on the image frame
    detections = detect(image_np)
    #Draw results
    image_np_with_detections = draw_results(detections, image_np, min_score_thresh=0.4)
    resized_result = cv2.resize(image_np_with_detections,(800,600))
    cv2.imshow('Object Detection',resized_result)
    
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break

camera.release()
cv2.destroyAllWindows()

#%%
    
